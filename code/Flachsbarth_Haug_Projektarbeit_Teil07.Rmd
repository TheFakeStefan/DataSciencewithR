---
title: "Projektarbeit Stefan Flachsbarth & Martin Haug<br/><br/>Teil 7 - Textmining Sentiment Analyse"
subtitle: "<br/>Analyse von Wahlergebnissen, Strukturdaten und Presseberichterstattung<br/>Bundestagswahlen im Zeitraum 1990 - 2017"
author: "<br/><br/>Stefan Flachsbarth, Martin Haug"
date: "`r Sys.Date()`"
output:
  html_document: 
    fig_height: 8
    fig_width: 12
    highlight: tango
    theme: paper
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: '3'
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```


## 7. Pressetexte zur Bundestagswhl - Sentiment-Analyse

### 7.1. Vorbereitung

#### Installation der benötigten R-Pakete

```{r, eval=FALSE}

install.packages(c("dplyr", "gutenbergr", "stringr", "tidytext", "tidyr", "stopwords", "wordcloud", "rsample", "glmnet", "doMC", "forcats", "broom", "igraph", "ggraph", "yardstick", "kableExtra", "readr", "widly", "wordcloud2"))

```

#### Laden der Bibliotheken

```{r, message=FALSE }
library(DBI)
library(dplyr)
library(forcats)
library(ggplot2)
library(ggraph)
library(igraph)
library(knitr)
library(kableExtra)
library(readr)
library(stopwords) 
library(stringr)
library(tibble)
library(tidyr)
library(tidytext)
library(widyr)
```

#### Auslesen der Daten

```{r}

KillDbConnections <- function () {
  all_cons <- dbListConnections(PostgreSQL())
  for(x in all_cons) +  dbDisconnect(x)
}

ReadPresseTablebyYear <- function(table_name, year) {
  # Initierung der Datenbank
  con <- dbConnect(RPostgreSQL::PostgreSQL(),
    host = 'hdm-sql.think-data.de', 
    dbname = 'postgres',
    user = 'postgres',
    password = '%%CENSORED%%'
    # Der richtige Weg, um auf sichere Weise das Passwort abzufragen
    #password = rstudioapi::askForPassword("Database password")
    )
  
  # Konstruktion der Query
  query <- paste("SELECT * FROM ", table_name, " WHERE filename LIKE '%", year, "%'",sep="")

  # Ausführen der Query und Zurückgeben des Ergebnisses
  return(dbGetQuery(con, query))
  
  # Verbindungsabbau
  KillDbConnections()
}
ReadPresseTable <- function(table_name) {
  # Initierung der Datenbank
  con <- dbConnect(RPostgreSQL::PostgreSQL(),
    host = 'hdm-sql.think-data.de', 
    dbname = 'postgres',
    user = 'postgres',
    password = '%%CENSORED%%'
    # Der richtige Weg, um auf sichere Weise das Passwort abzufragen
    #password = rstudioapi::askForPassword("Database password")
    )

  # Auslesen der Tabelle und Zurückgeben des Ergebnisses
  return(dbReadTable(con, table_name))
  
  # Verbindungsabbau
  KillDbConnections()
}

# Daten über die Funktion einlesen
presse2009 <- ReadPresseTablebyYear("presse", 2009)
presse <- ReadPresseTable("presse")

kable(head(presse,1)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "200px")

```

#### Auslesen der Daten mit Dplyr

```{r, eval=FALSE}

# Dplyr hat mittlerweile auch Funktionen, um Daten von PostgreSQL zu lesen.

KillDbConnections <- function () {
  all_cons <- dbListConnections(PostgreSQL())
  for(x in all_cons) +  dbDisconnect(x)
}

ReadData <- function(table_name, year) {
  # Initierung der Datenbank
  con <- src_postgres(
    host = 'hdm-sql.think-data.de', 
    dbname = 'postgres',
    user = 'postgres',
    password = '%%CENSORED%%'
    # Der richtige Weg, um auf sichere Weise das Passwort abzufragen
    #password = rstudioapi::askForPassword("Database password")
    )
  
  # Konstruktion der Query
  query <- paste("SELECT * FROM ", table_name, " WHERE filename LIKE '%", year, "%'",sep="")

  # Auslesen der Daten
  return(tbl(con, sql(query)))
  
  # Verbindung lösen
  KillDbConnections()
}

# Daten über die Funktion einlesen
presse2009_dplyr <- ReadData("presse", 2009)

```

#### Transformation der Daten

```{r}

# Anpassen der Daten
presse_cleaned <- presse
# Filtern von Inhalten wie "$publikation vom 01.01.2001 ..."
presse_cleaned$publisher <- gsub(" vom.*$", "", presse_cleaned$publisher, ignore.case = TRUE)
# Filtern von Inhalten wie "$publikation print: Nr. 1 ..."
presse_cleaned$publisher <- gsub(" print: nr. \\d.*$", "", presse_cleaned$publisher, ignore.case = TRUE)
# Filtern von Inhalten wie "$publikation Nr. 1 ..."
presse_cleaned$publisher <- gsub(" nr. \\d.*$", "", presse_cleaned$publisher, ignore.case = TRUE)
# Filtern von Inhalten wie "$publikation, Jg. 52, 01.01.2001 ..."
presse_cleaned$publisher <- gsub(", Jg. \\d.*$", "", presse_cleaned$publisher, ignore.case = TRUE)
# Filtern von Inhalten wie "$publikation, 01.01.2001, S. 1 ..."
presse_cleaned$publisher <- gsub(", \\d\\d.\\d\\d.\\d\\d\\d\\d.*$", "", presse_cleaned$publisher, ignore.case = TRUE)
# Filtern von Inhalten wie "$publikation Nr. ..."
presse_cleaned$publisher <- gsub("Nr. *$", "", presse_cleaned$publisher, ignore.case = TRUE)

# Vereinheitlichen der Groß- und Kleinschreibung
# Entfernen aller Leerzeichen vor und nach den Publikationen
presse_cleaned$publisher <- tolower(presse_cleaned$publisher) %>% trimws()

```

***

### 7.2. Text Mining

#### Tokenization

```{r}

# Extraktion der Token aus den Artikelüberschriften
token_header <- unnest_tokens(as_tibble(presse_cleaned), word, header, token = "words", format = "text", to_lower = TRUE, drop = TRUE)

# Extraktion der Token aus den Artikeltexten
token_text <- unnest_tokens(as_tibble(presse_cleaned), word, text, token = "words", format = "text", to_lower = TRUE, drop = TRUE)

# Visualisierung der Ergebnisse der Prozeduren
kable(head(token_header,1)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "200px")

kable(head(token_text,1)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "200px")

```

#### Stopwords

```{r}

# Liste mit deutschen Stopwords
stopword <- as_tibble(stopwords::stopwords("de")) 
stopword <- rename(stopword, word=value)

# Erweiterte Liste mit deutschen Stopwords
stopword_extented <- read_tsv("https://raw.githubusercontent.com/solariz/german_stopwords/master/german_stopwords_full.txt", col_names = FALSE, comment = ";")
stopword_extented <- rename(stopword_extented, word=X1)

# Liste der eigenen Stopwords
# bz ist das Kürzel der Badischen Zeitung
# mz ist das Kürzel der Mitteldeutschen Zeitung
# rp ist das Kürzel der Rheinischen Post
# sz ist das Kürzel der Sächsischen Zeitung
# ta ist das Kürzel der Thüringer Allgemeinen
# taz ist das Kürzel der tageszeitung
# tz ist das Kürzel der tz (münchner zeitung)
stopword_own <- tibble(word = c("bz", "mz", "rp", "sz", "tz", "ta", "taz"))

# Zusammenfügen und Entfernen von Duplikaten
all_stopword <- bind_rows(stopword,stopword_extented, stopword_own) %>% distinct()

tb_header <- anti_join(token_header, all_stopword, by = 'word')
tb_text <- anti_join(token_text, all_stopword, by = 'word')

# Visualisierung der Ergebnisse der Prozeduren
kable(head(tb_header,1)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "200px")

kable(head(tb_text,1)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "200px")

```


***

### 7.3. Sentimentanalyse

#### Aufbau des Sentiment-Dataframes

Die Universität Leipzig hat eine großartige Liste mit Sentiments von Wörtern in deutscher Sprache zur Verfügung gestellt, welche in Rahmen der Sentimentanalyse genutzt werden soll. Das Paket wurde von dem nachfolgenden Link heruntergeladen, entpackt und auf GitHub hochgeladen.

* http://pcai056.informatik.uni-leipzig.de/downloads/etc/SentiWS/SentiWS_v2.0.zip

```{r}

negative_worte <- read_tsv("https://github.com/TheFakeStefan/DataSciencewithR/raw/master/sentiment/SentiWS_v2.0_Negative.txt", col_names = FALSE)
names(negative_worte) <- c("Wort_POS", "Wert", "Inflektionen")
negative_worte <- negative_worte %>% 
  mutate(Wort = str_sub(Wort_POS, 1, regexpr("\\|", .$Wort_POS)-1),
         POS = str_sub(Wort_POS, start = regexpr("\\|", .$Wort_POS)+1))


positive_worte <- read_tsv("https://github.com/TheFakeStefan/DataSciencewithR/raw/master/sentiment/SentiWS_v2.0_Positive.txt", col_names = FALSE)
names(positive_worte) <- c("Wort_POS", "Wert", "Inflektionen")

positive_worte <- positive_worte %>% 
  mutate(Wort = str_sub(Wort_POS, 1, regexpr("\\|", .$Wort_POS)-1),
         POS = str_sub(Wort_POS, start = regexpr("\\|", .$Wort_POS)+1))

sentiment_df <- bind_rows("neg" = negative_worte, "pos" = positive_worte, .id = "neg_pos")
sentiment_df <- sentiment_df %>% select(neg_pos, Wort, Wert, Inflektionen, -Wort_POS)

```

#### Analyse der Artikelüberschriften

```{r}

sentiment_header_neg <- match(tb_header$word, filter(sentiment_df, neg_pos == "neg")$Wort)
neg_score <- sum(!is.na(sentiment_header_neg))

sentiment_header_pos <- match(tb_header$word, filter(sentiment_df, neg_pos == "pos")$Wort)
pos_score <- sum(!is.na(sentiment_header_pos))

round(pos_score/neg_score, 1)

```

##### Interpretation

Die **Sentiment-Analyse der Presseberichte zeigt eine leichte Tendenz ins Positive**. Der Postiv-Wert ist 1,4 mal so groß wie der Negativ-Wert.


#### Analyse der Artikeltexte

```{r}

sentiment_text_neg <- match(tb_text$word, filter(sentiment_df, neg_pos == "neg")$Wort)
neg_score <- sum(!is.na(sentiment_text_neg))

sentiment_text_pos <- match(tb_text$word, filter(sentiment_df, neg_pos == "pos")$Wort)
pos_score <- sum(!is.na(sentiment_text_pos))

round(pos_score/neg_score, 1)

```

##### Interpretation

Eine **ähnliche Tendenz zeigt sich auch bei der Sentiment-Analyse der Artikeltexte** - sogar noch etwas ausgeprägter. Der Postiv-Wert ist hier 2x so groß wie der Negativ-Wert in den Artikeltexten.


#### Darstellung der postiven und negativen Worte

```{r}

tb_header_sentiment <- tb_header %>% 
  mutate(sentiment_header_neg = sentiment_header_neg,
         sentiment_header_pos = sentiment_header_pos) 

tb_header_neg_sentiment <- tb_header %>% 
  filter(!is.na(sentiment_header_neg)) %>% 
  dplyr::select(word)

tb_header_pos_sentiment <- tb_header %>% 
  filter(!is.na(sentiment_header_pos)) %>% 
  dplyr::select(word)

kable(head(tb_header_neg_sentiment,10)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

kable(head(tb_header_pos_sentiment,10)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) 

```

##### Interpretation

Diese Aufstellung vermittelt ein etwas genaueres Bild darüber, welche Begriffe als positiv beziehungsweise negativ gewertet wurden. 
Bislang blieb die unterschiedliche Anzahl der Begriffe völlig unberücksichtigt. Diese sollen nun etwas genauer betrachtet werden.


#### Sentiment-Analyse der Artikelüberschriften

```{r}

tb_header_sentiment_neg_count <- tb_header_sentiment %>% 
  filter(!is.na(sentiment_header_neg)) %>% 
  summarise(n_distinct_neg = n_distinct(word)) %>%
  rename("Anzahl der negativen Wörter" = "n_distinct_neg")

kable(tb_header_sentiment_neg_count) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

tb_header_sentiment_pos_count <- tb_header_sentiment %>% 
  filter(!is.na(sentiment_header_pos)) %>% 
  summarise(n_distinct_pos = n_distinct(word))  %>%
  rename("Anzahl der positiven Wörter" = "n_distinct_pos")

kable(tb_header_sentiment_pos_count) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```

```{r}
sentiment_df <- sentiment_df %>% 
  rename(word = Wort)

tb_header_mit_senti <- tb_header %>% 
  left_join(sentiment_df, by="word") 

tb_header_senti_gesamt <- tb_header_mit_senti %>% 
  filter(!is.na(Wert)) %>% 
  summarise(Sentimentwert = sum(Wert, na.rm = TRUE))

kable(tb_header_senti_gesamt) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

tb_header_senti_pos_neg <- tb_header_mit_senti %>% 
  group_by(neg_pos) %>% 
  filter(!is.na(Wert)) %>% 
  summarise(Wert = sum(Wert)) %>%
  rename(Sentiment = neg_pos)

kable(tb_header_senti_pos_neg) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```

##### Interpretation

Das Ergebnis ist überraschend. **Während die Anzahl der positiven Wörter diejenige der negativen Wörter deutlich übersteigt, sieht die Situation beim Sentimentwert (also der Gewichtung) anders aus**. Die postiven Worte sind weniger ausdruckstark als die negativen Wörter.

```{r}
tb_header_pos_top10 <- tb_header_mit_senti %>% 
  filter(neg_pos == "pos") %>% 
  distinct(word, .keep_all = TRUE) %>% 
  arrange(-Wert) %>% 
  filter(row_number() < 11) %>% 
  dplyr::select(word, Wert)

kable(tb_header_pos_top10) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```

```{r}
tb_header_neg_top10 <- tb_header_mit_senti %>% 
  filter(neg_pos == "neg") %>% 
  distinct(word, .keep_all = TRUE) %>% 
  arrange(Wert) %>% 
  filter(row_number() < 11) %>% 
  dplyr::select(word, Wert)

kable(tb_header_neg_top10) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```


#### Verteilung der Wörter

```{r}

tb_header_mit_senti %>% 
  filter(!is.na(Wert)) %>% 
  ggplot() +
  aes(x = Wert) +
  xlab("Sentimentwert") +
  ylab("Anzahl der Wörter") +
  geom_histogram(fill="steelblue")

```

```{r}
tb_header_senti_total_table <- tb_header_mit_senti %>% 
  filter(!is.na(Wert)) %>% 
  dplyr::count(neg_pos)

kable(tb_header_senti_total_table) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

##### Interpretation

In der Artikelüberschriften finden sich deutlich mehr positive als negative Wörter.


#### Sentiment des Sentimentverzeichnisses

Wie ist eigentlich das Sentiment des Sentiments?

```{r}

sentiment_senti_sum  <- sentiment_df %>% 
  filter(!is.na(Wert)) %>% 
  summarise(sentiment_summe = sum(Wert))

kable(sentiment_senti_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```

```{r}
relativ_senti_header <- as.data.frame(sentiment_senti_sum$sentiment_summe / tb_header_senti_gesamt$Sentimentwert)

kable(sentiment_senti_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```

##### Interpretation

Der relative Sentimentswert drückt aus, wie sich der gemessene Sentimentswert zu dem durchschnittlichen Sentimentswert aller im Sentimentsverzeichnis untersuchten Texte verhält. Der **relative Sentimentswert der Artikelüberschriften (relativ zum Sentimentverzeichnis) beträgt in diesem Falle ~19.5, ist also etwas positiver als der durchschnittliche Sentimentswert**.

***

### 7.4. Analyse des Sentiments zwischen Ost- und Westpublikation aus dem Jahr 2017

```{r}

tb_text_basische_zeitung <- tb_text %>% 
  filter(year == 2009) %>%
  filter(publisher == "badische zeitung") 

tb_text_basische_zeitung_sentiment_neg <- 
  match(tb_text_basische_zeitung$word, filter(sentiment_df, neg_pos == "neg")$word)

tb_text_basische_zeitung_neg_score <- 
  sum(!is.na(tb_text_basische_zeitung_sentiment_neg))

tb_text_basische_zeitung_sentiment_pos <- 
  match(tb_text_basische_zeitung$word, filter(sentiment_df, neg_pos == "pos")$word)
tb_text_basische_zeitung_pos_score <- 
  sum(!is.na(tb_text_basische_zeitung_sentiment_pos))

round(tb_text_basische_zeitung_pos_score/tb_text_basische_zeitung_neg_score, 1)

```

##### Interpretation

Die Badische Zeitung aus Freiburg weist einen Sentiment-Wert von 2x auf. Der Positiv-Wert ist also 2x so groß wie der Negativ-Wert in den Artikeltexten des Blattes.

```{r}

tb_text_saechsische_zeitung <- tb_text %>% 
  filter(year == 2009) %>%
  filter(publisher == "sächsische zeitung") 

tb_text_saechsische_zeitung_sentiment_neg <- 
  match(tb_text_saechsische_zeitung$word, filter(sentiment_df, neg_pos == "neg")$word)
tb_text_saechsische_zeitung_neg_score <- 
  sum(!is.na(tb_text_saechsische_zeitung_sentiment_neg))

tb_text_saechsische_zeitung_sentiment_pos <- 
  match(tb_text_saechsische_zeitung$word, filter(sentiment_df, neg_pos == "pos")$word)
tb_text_saechsische_zeitung_pos_score <- 
  sum(!is.na(tb_text_saechsische_zeitung_sentiment_pos))

round(tb_text_saechsische_zeitung_pos_score/tb_text_saechsische_zeitung_neg_score, 1)

```

##### Interpretation

Bei der Sächsischen Zeitung aus Dresden ist der Sentiment-Wert mit 2,5x sogar noch etwas höher als bei der Badischen Zeitung. Der Postiv-Wert ist hier also 2,5x so groß wie der Negativ-Wert in den Artikeltexten und damit 0,5 Punkte positiver als die badische Zeitung.

***

### 7.5. Vergleich des Sentiments der vergangenen Wahljahre

```{r}

# Definieren der Funktion
getSentiment <- function(text,jahr) {
  x <- text %>% filter(year == jahr) 
  
  x_senti_neg <- match(x$word, filter(sentiment_df, neg_pos == "neg")$word)
  x_neg_score <- sum(!is.na(x_senti_neg))
  
  x_senti_pos <- match(x$word, filter(sentiment_df, neg_pos == "pos")$word)
  x_pos_score <- sum(!is.na(x_senti_pos))
  # Wir fangen hier mögliche Nullwerte von x_neg_score ab
  y <- ifelse(is.infinite(x_pos_score/x_neg_score),x_pos_score,x_pos_score/x_neg_score) %>% as.numeric()
  print(paste("Der Sentiment für das Jahr", jahr, "beträgt", y))
  return(tibble(y,jahr))
}

senti_header_1990 <- getSentiment(tb_header, "1990")
senti_header_1994 <- getSentiment(tb_header, "1994")
senti_header_1998 <- getSentiment(tb_header, "1998")
senti_header_2002 <- getSentiment(tb_header, "2002")
senti_header_2005 <- getSentiment(tb_header, "2005")
senti_header_2009 <- getSentiment(tb_header, "2009")
senti_header_2013 <- getSentiment(tb_header, "2013")
senti_header_2017 <- getSentiment(tb_header, "2017")

senti_header_all <- rbind(senti_header_1990,
                          senti_header_1994,
                          senti_header_1998,
                          senti_header_2002,
                          senti_header_2005,
                          senti_header_2009,
                          senti_header_2013,
                          senti_header_2017)

senti_header_all$source <- "Titel"
  
senti_text_1990 <- getSentiment(tb_text, "1990")
senti_text_1994 <- getSentiment(tb_text, "1994")
senti_text_1998 <- getSentiment(tb_text, "1998")
senti_text_2002 <- getSentiment(tb_text, "2002")
senti_text_2005 <- getSentiment(tb_text, "2005")
senti_text_2009 <- getSentiment(tb_text, "2009")
senti_text_2013 <- getSentiment(tb_text, "2013")
senti_text_2017 <- getSentiment(tb_text, "2017")

senti_text_all <- rbind(senti_text_1990,
                        senti_text_1994,
                        senti_text_1998,
                        senti_text_2002,
                        senti_text_2005,
                        senti_text_2009,
                        senti_text_2013,
                        senti_text_2017)

senti_text_all$source <- "Text"
senti_all <- rbind(senti_header_all,senti_text_all) 

# Plotten der Grafik
ggplot(data=senti_all, aes(x=jahr, y=y, fill=source )) +
  geom_bar(stat="identity",
          position=position_dodge())+
  xlab("Jahr") +
  ylab("Sentiment") +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  ggtitle("Vergleich der Sentimente über die vergangenen Wahljahre")

```

##### Interpretation

In der **Langzeitanalyse zeigt sich, dass der Sentiment-Wert der Artikeltexte sich relativ stabil im positien Bereich in einem Korridor von rund 1,5x bis etwas über 2x bewegt**. Der **Sentiment-Wert der Überschriften** ist jedoch fast üben den gesamten Zeitraum hinweg **leicht bis deutlich unter dem Wert der Artikeltexte**. Das Jahr 1990 bildet hier eine Ausnahme. Hier sieht man eine größere Zahl euphorischer Überschriften, vermutlicht bedingt durch die positive Berichterstattung zur deutschen Einheit, die im unmittelbaren Vorfeld der Bundestagswahl 1990 stattfand. 


